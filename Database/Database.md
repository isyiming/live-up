

### 数据库架构

  第一层：客户端与服务端建立连接所必须的：链接处理，安全认证，权限认证等等    
  第二层：数据库提供的核心服务功能：查询解析，分析，优化等，各种服务器所能提供的内置函数
  第三层：存储引擎：负责数据的存储和提取

其实就向其他知识块一样，它其实也是为了解决某种问题而设计的系统。也存在一个根本的矛盾：安全稳定和性能的矛盾。要想获得安全性，那必然要对人为的操作设计一些限制，而这些额外的限制就会降低系统性能。

1.事务：

简单来说，就是对数据库的一个操作，这个操作的特殊在于，如果没有完全执行，结果就不会写入数据库。为了尽量保证数据库的稳定，操作符合我们的预期，就要设计几条原则：这其实就是事务的4个属性。事务满足这四条原则的操作，就是我们定义的事务。
  * 原子性：事务操作要么成功，要不失败回滚到最初状态（转账过程中，仅仅給账户A扣钱，没给账户B转钱）
  实现原理：日志回滚

  * 隔离性：多用户并行访问数据库时，多个并发事务要隔离。同一时间，只允许一个事务请求同一数据，不同的事物之间彼此没有干扰。
  实现原理：MVCC（多版本并发控制）和锁

  * 持久性：持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。
  实现原理：redo log。数据修改是将数据读取到内存中操作的，同时也会将操作存入日志。
  这样当服务器出现意外的时候，可以根据日志恢复数据，决定到底是回滚还是提交。

  * 一致性：事务操作后，数据库的状态从状态1到了状态2，这个数据库的前后状态对数据库的条目而言都是合理的，符合规则的。
  （以上三个特性保证了事务具有一致性）

2.事务日志

  存储引擎在修改表时，只需要修改其内存拷贝，再将修改行为追加记录到硬盘中的事务日志中。
  日志持久后，再根据日志，在后台将修改的数据刷到硬盘。
  所以修改数据需要写两次硬盘。有了日志，就可以支持回滚操作。

3.并发一致性的问题
我们期望数据库是一个非常稳定的系统。但是总会有各种意外情况，尤其是并发操作时，我可以举几个并发一致性的例子：
  * 丢失修改：一个事务对数据进行了修改，在事务提交之前，另一个事务对同一个数据进行了修改，覆盖了之前的修改。
  * 脏读（Dirty Read）：一个事务读取了被另一个事务修改、但未提交（进行了回滚）的数据，造成两个事务得到的数据不一致；
  * 不可重复读（Nonrepeatable Read）：在同一个事务中，某查询操作在一个时间读取某一行数据和之后一个时间读取该行数据，发现数据已经发生修改（可能被更新或删除了）；
  * 幻读（Phantom Read）：当同一查询多次执行时，由于其它事务在这个数据范围内执行了插入操作，会导致每次返回不同的结果集（和不可重复读的区别：针对的是一个数据整体/范围；并且需要是插入操作）

4.对应的隔离级别
以上并发一致性带来的问题，是因为并发操作破坏了事务隔离性，就会引起这么多可能的错误。那么对并发事务进行不同程度的隔离后，四个隔离级别：
  * 未提交读：还没有提交的事务的修改，对其他事物也是可见的。这就完全没有隔离性。会带来脏读和丢失修改的问题。啥问题都没解决。
  * 提交读（不可重复读）：一个进行读取操作的事务，只能看见已经提交的事务所做的修改。解决了脏读。（mysql默认级别）
  * 可重复读：读取事务一开始读取，就将读取数据加了悲观锁，其他事物就无法修改这些数据了。就可以保证可重复读。解决了脏读和不可重复读问题。
  * 可串行化：强制所有事务串行执行，那就没有并发了，也就没有各种并发一致性的问题。

5.并发控制

为了防止并发操作带来的问题，就需要給事务操作上锁。
读写锁：
  * 共享锁，读锁，允许多进程同时读取数据库，但是禁止同时有写入操作
  * 排他锁，写锁，一个进程就会阻止其他进程同时读取和写入操作。

锁粒度：
  * 同样是基本矛盾引起的问题：锁使得数据库操作更安全，但是针对锁本身的操作拉低了数据库的性能。比如每次事务都需要获取锁状态，会增加系统开销。
  * 另外如果事务A在进行写入操作，但是事务B想要读取数据库中另外一部分数据。A对B本构不成影响，但是因为拍他锁的存在，B访问不了数据库。
  * 解决的办法就是调整锁粒度。让锁定的数据范围尽可能的小，这样对并发操作的影响就会减小。但是较小粒度的锁带来的服务器系统开销就大了。比如锁定一行，那就需要事务对每一行操作时都要判断是否是不是锁定的一行。当然，也可以优化，比如仅仅对当前表的每一行进行判断。
* mysql的锁粒度：表锁，行级锁。
* 高级别的安全措施带来了性能降低。

什么是乐观锁和悲观锁？
  * 悲观锁：认为数据随时会被修改，因此每次读取数据之前都会上锁，防止其它事务读取或修改数据；应用于数据更新比较频繁的场景；
  * 乐观锁：操作数据时不会上锁，但是更新时会判断在此期间有没有别的事务更新这个数据，若被更新过，则失败重试；适用于读多写少的场景。乐观锁的实现方式有：
    * 加一个版本号或者时间戳字段，每次数据更新时同时更新这个字段；
    * 先读取想要更新的字段或者所有字段，更新的时候比较一下，只有字段没有变化才进行更新

死锁
多个事务在同一资源上相互占用，请求锁定对方占用的资源，导致恶性循环。
解决死锁：
* 将持有最少行政级排它锁的事务进行回滚。
* 等待超时后放弃锁请求。

6.索引 键 Key
* 索引是对数据库表中一列或多列的值进行排序的一种结构，使用索引可快速访问数据库表中的特定信息。
* 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。
* 可以大大加快数据的检索速度，这也是创建索引的最主要的原因。
* 缺点：
    * 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。
    * 索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间
    * 当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。
* 创建索引的原则：维护索引的代价小，检索的性能有很大提高时

7.数据库索引的类型有哪些？数据结构是什么样的，各自有哪种适应场景。
  * 唯一索引：在创建唯一索引时要不能给具有相同的索引值。
  * 主键索引：在我们给一个字段设置主键的时候，它就会自动创建主键索引，用来确保每一个值都是唯一的。
  * 聚集索引：我们在表中添加数据的顺序，与我们创建的索引键值相同，而且一个表中只能有一个聚集索引。
  * 普通索引：它的结构主要以B+树和哈希索引为主，主要是对数据表中的数据进行精确查找。
  * 全文索引：它的作用是搜索数据表中的字段是不是包含我们搜索的关键字，就像搜索引擎中的模糊查询。

  * B-Tree索引
* 每个x节点都存有n个关键字x.key，关键字以非降序排列
    * 每个x节点都存有一个布尔值x.left，如果x是叶节点，left=True，x为内部节点为False
    * 每个内部节点还包含n+1个指向其孩子的指针。
* 关键字x.key对存储在各子树中的关键字范围加以分割。
* 每个叶节点具有相同的深度，即树的高度h。
* 每个节点锁包含的关键字个数t-1<n<2t-1 ，恰好包含2t-1时，满节点
为什么是B-Tree？
* 硬件角度分析：
    *     因为索引是保存在磁盘中的，机械硬盘的IO操作需要探针移动，这个移动是比较耗时的。所以磁盘在读取数据的时候总是会预读。数据库设计时，将B-tree的一个节点大小设置为磁盘的一页，这样在访问一个节点的时候就可以充分利用磁盘的预读数据。
* 查找效率分析：
    * 另外，查找树的查找效率是非常高的。平衡二叉树的效率更高些，但是插入删除成本也高，一个妥协的方法就是红黑树，这个也是map的原理。但是红黑树的深度相比B-Tree更深，而且单个节点只有一个元素。遍历红黑树的磁盘IO操作更频繁。

B+树的关键字全部存放在叶子节点中，非叶子节点用来做索引，而叶子节点中有一个指针指向一下个叶子节点。做这个优化的目的是为了提高区间访问的性能。而正是这个特性决定了B+树更适合用来存储外部数据。
 “B+树还有一个最大的好处，方便扫库，B树必须用中序遍历的方法按序扫库，而B+树直接从叶子结点挨个扫一遍就完了，B+树支持range-query非常方便，而B树不支持。这是数据库选用B+树的最主要原因。

9.什么是套嵌事务？

二叉查找树：左子树任意节点都<node<右子树任意节点
平衡二叉树：在符合查找树的条件下，任何节点的两个子树高度差<=1

对象关系映射（Object Relational Mapping，简称ORM）是通过使用描述对象和数据库之间映射的元数据，将面向对象语言程序中的对象自动持久化到关系数据库中。

3.inner join 和left join
* 左连接：返回包括左表中的所有记录和右表中联结字段相等的记录
* inner join：(等值连接)只返回两个表中联结字段相等的行
